{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a reinforcement model to play hit stationary target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libiaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries for SpaceShooter game\n",
    "import pygame\n",
    "import random\n",
    "from enum import Enum\n",
    "import time\n",
    "import os\n",
    "from random import randint\n",
    "import numpy as np\n",
    "\n",
    "# Import libraries for the Model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Import libraries for plot function \n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "\n",
    "# Import libraries for the Agent\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialise settings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pygame.font.init()\n",
    "pygame.mixer.init()\n",
    "\n",
    "WIDTH, HEIGHT = 900, 500\n",
    "WIN = pygame.display.set_mode((WIDTH, HEIGHT))\n",
    "BORDER = pygame.Rect(WIDTH//2 - 5, 0, 10, HEIGHT)\n",
    "HEALTH_FONT = pygame.font.SysFont('comicsans', 40)\n",
    "WINNER_FONT = pygame.font.SysFont('comicsans', 100)\n",
    "FPS = 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set colours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BLACK = (0, 0, 0)\n",
    "RED = (255, 0, 0)\n",
    "YELLOW = (255, 255, 0)\n",
    "PURPLE = (200, 0, 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialise physics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VEL = 20\n",
    "BULLET_VEL = 50\n",
    "SPACESHIP_WIDTH, SPACESHIP_HEIGHT = 55, 40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialise images and sounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "YELLOW_HIT = pygame.USEREVENT + 1\n",
    "RED_HIT = pygame.USEREVENT + 2\n",
    "\n",
    "# Heart image\n",
    "HEART_IMAGE = pygame.image.load(os.path.join('Assets', 'heart.png')).convert_alpha()\n",
    "HEART = pygame.transform.scale(HEART_IMAGE, (40, 40))\n",
    "\n",
    "# Yellow spaceShip image\n",
    "YELLOW_SPACESHIP_IMAGE = pygame.image.load(os.path.join('Assets', 'spaceship_yellow.png'))\n",
    "YELLOW_SPACESHIP = pygame.transform.rotate(pygame.transform.scale(YELLOW_SPACESHIP_IMAGE, (SPACESHIP_WIDTH, SPACESHIP_HEIGHT)), 90)\n",
    "\n",
    "# Red spaceship image\n",
    "RED_SPACESHIP_IMAGE = pygame.image.load(os.path.join('Assets', 'spaceship_red.png'))\n",
    "RED_SPACESHIP = pygame.transform.rotate(pygame.transform.scale(RED_SPACESHIP_IMAGE, (SPACESHIP_WIDTH, SPACESHIP_HEIGHT)), 270)\n",
    "\n",
    "# Backround image\n",
    "SPACE = pygame.transform.scale(pygame.image.load(os.path.join('Assets', 'space_background_2.jpg')), (WIDTH, HEIGHT))\n",
    "\n",
    "# Game sounds\n",
    "BULLET_HIT_SOUND = pygame.mixer.Sound('Assets/Grenade+1.mp3')\n",
    "BULLET_FIRE_SOUND = pygame.mixer.Sound('Assets/Gun+Silencer.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Action(Enum):\n",
    "    UP = 1\n",
    "    DOWN = 2\n",
    "    FIRE = 3\n",
    "    NOTHING = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build enviroment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpaceShooter:\n",
    "\n",
    "    def __init__(self):\n",
    "        #Init display\n",
    "        pygame.display.set_caption(\"SpaceShooterAI\")\n",
    "        self.BORDER = pygame.Rect(WIDTH//2 - 5, 0, 10, HEIGHT)\n",
    "        self.clock = pygame.time.Clock()\n",
    "        self.reset()\n",
    "          \n",
    "    def reset(self):\n",
    "       # Reset game state\n",
    "        self.red = pygame.Rect(700, 230, SPACESHIP_WIDTH, SPACESHIP_HEIGHT)\n",
    "        self.yellow = pygame.Rect(100, 230, SPACESHIP_WIDTH, SPACESHIP_HEIGHT)\n",
    "        self.yellow_bullet = None\n",
    "        self.red_health = 0\n",
    "        self.yellow_health = 1 \n",
    "        self.frame_iteration = 0\n",
    "        self.YELLOW_BULLET_FLAG = 0\n",
    "        self.RED_BULLET_FLAG = 0\n",
    "        self.action = Action.NOTHING\n",
    "        \n",
    "        \n",
    "    def step(self, action):\n",
    "        self.frame_iteration += 1\n",
    "        # 1. Collect user input and perform action \n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:\n",
    "                pygame.quit()\n",
    "                quit()\n",
    "            \n",
    "        # [UP, DOWN, FIRE, NOTHING]\n",
    "        if np.array_equal(action, [1, 0, 0]) and self.yellow.y - VEL > 0: # UP\n",
    "            self.action = Action.UP\n",
    "            self.yellow.y -= VEL\n",
    "        elif np.array_equal(action, [0, 1, 0]) and self.yellow.y + VEL + self.yellow.height < HEIGHT - 15: # DOWN\n",
    "            self.action = Action.DOWN\n",
    "            self.yellow.y += VEL\n",
    "        elif np.array_equal(action, [0, 0, 1]) and self.YELLOW_BULLET_FLAG == 0: # FIRE\n",
    "            self.action = Action.FIRE\n",
    "            self.yellow_bullet = pygame.Rect(self.yellow.x + self.yellow.width, self.yellow.y + self.yellow.height//2, 10, 5)\n",
    "            self.YELLOW_BULLET_FLAG = 1\n",
    "            # BULLET_FIRE_SOUND.play() uncomment if you want sound :)\n",
    "        \n",
    "        # Check is game is over \n",
    "        game_over = False \n",
    "        reward = 0\n",
    "        if self.yellow_bullet != None:\n",
    "            self.yellow_bullet.x += BULLET_VEL\n",
    "            \n",
    "            if self.red.colliderect(self.yellow_bullet):\n",
    "                reward = 10\n",
    "                \n",
    "                # Red spaceship new position new \n",
    "                self.red_pseudo_y = randint(40, 400)\n",
    "                nearest_multiple_20 = 20 * round(self.red_pseudo_y/20)\n",
    "                self.red_new_y = nearest_multiple_20\n",
    "                self.red = pygame.Rect(self.red.x, self.red_new_y, SPACESHIP_WIDTH, SPACESHIP_HEIGHT)\n",
    "                self.red_health += 1\n",
    "                \n",
    "                # Handle yellow bullet\n",
    "                self.yellow_bullet = None\n",
    "                self.YELLOW_BULLET_FLAG = 0\n",
    "                return game_over, self.red_health, reward\n",
    "                \n",
    "            elif self.yellow_bullet.x > WIDTH:\n",
    "                reward = -10\n",
    "                game_over = True\n",
    "                return game_over, self.red_health, reward\n",
    "\n",
    "        # 3. Check if game is over    \n",
    "        if self.red_health >= 1000:\n",
    "            reward = 10\n",
    "            game_over = True\n",
    "            self.winner_text = \"TriBlaster beast!\"\n",
    "            self.winner_colour = YELLOW\n",
    "            self.draw_winner()\n",
    "            return game_over, self.red_health, reward\n",
    "        \n",
    "        if self.frame_iteration > 50*(self.red_health+1):\n",
    "            reward = -10\n",
    "            game_over = True\n",
    "            return game_over, self.red_health, reward\n",
    "        \n",
    "        # 4. Update UI and Clock \n",
    "        self.draw_window()\n",
    "        self.clock.tick(FPS)\n",
    "        return game_over, self.red_health, reward \n",
    "        \n",
    "    #Render\n",
    "    def draw_window(self):\n",
    "        WIN.blit(SPACE, (0, 0))\n",
    "        pygame.draw.rect(WIN, PURPLE, BORDER)\n",
    "\n",
    "        self.red_health_text = HEALTH_FONT.render(str(self.red_health), 1, RED)\n",
    "        self.yellow_health_text = HEALTH_FONT.render(str(self.yellow_health), 1, RED)\n",
    "        \n",
    "        # Draw score\n",
    "        WIN.blit(HEART, (WIDTH - 150, 17))\n",
    "        WIN.blit(self.red_health_text, (WIDTH - 100, 10))\n",
    "        \n",
    "        # Draw Spaceships\n",
    "        WIN.blit(YELLOW_SPACESHIP, (self.yellow.x, self.yellow.y))\n",
    "        WIN.blit(RED_SPACESHIP, (self.red.x, self.red.y))\n",
    "\n",
    "        # Draw yellow bullet\n",
    "        if self.yellow_bullet != None:\n",
    "            pygame.draw.rect(WIN, YELLOW, self.yellow_bullet)\n",
    "\n",
    "        pygame.display.update()   \n",
    "    \n",
    "    def draw_winner(self):\n",
    "        draw_text = WINNER_FONT.render(self.winner_text, 1, self.winner_colour)\n",
    "        WIN.blit(draw_text, (WIDTH/2 - draw_text.get_width() /2, HEIGHT/2 - draw_text.get_height()/2))\n",
    "        pygame.display.update()\n",
    "        pygame.time.delay(500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the model used to train the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear_QNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "\n",
    "    def save(self, file_name='model_record.pth'):\n",
    "        model_folder_path = './model'\n",
    "        if not os.path.exists(model_folder_path):\n",
    "            os.makedirs(model_folder_path)\n",
    "\n",
    "        file_name = os.path.join(model_folder_path, file_name)\n",
    "        torch.save(self.state_dict(), file_name)\n",
    "        \n",
    "    def save_250(self, file_name='model_250.pth'):\n",
    "        model_folder_path = './model'\n",
    "        if not os.path.exists(model_folder_path):\n",
    "            os.makedirs(model_folder_path)\n",
    "\n",
    "        file_name = os.path.join(model_folder_path, file_name)\n",
    "        torch.save(self.state_dict(), file_name)\n",
    "\n",
    "    def save_500(self, file_name='model_500.pth'):\n",
    "        model_folder_path = './model'\n",
    "        if not os.path.exists(model_folder_path):\n",
    "            os.makedirs(model_folder_path)\n",
    "\n",
    "        file_name = os.path.join(model_folder_path, file_name)\n",
    "        torch.save(self.state_dict(), file_name)\n",
    "        \n",
    "    def save_1000(self, file_name='model_1000.pth'):\n",
    "        model_folder_path = './model'\n",
    "        if not os.path.exists(model_folder_path):\n",
    "            os.makedirs(model_folder_path)\n",
    "\n",
    "        file_name = os.path.join(model_folder_path, file_name)\n",
    "        torch.save(self.state_dict(), file_name)\n",
    "\n",
    "class QTrainer:\n",
    "    def __init__(self, model, lr, gamma):\n",
    "        self.lr = lr\n",
    "        self.gamma = gamma\n",
    "        self.model = model\n",
    "        self.optimizer = optim.Adam(model.parameters(), lr=self.lr)\n",
    "        self.criterion = nn.MSELoss()\n",
    "\n",
    "    def train_step(self, state, action, reward, next_state, done):\n",
    "        state = torch.tensor(state, dtype=torch.float)\n",
    "        next_state = torch.tensor(next_state, dtype=torch.float)\n",
    "        action = torch.tensor(action, dtype=torch.long)\n",
    "        reward = torch.tensor(reward, dtype=torch.float)\n",
    "        # (n, x)\n",
    "\n",
    "        if len(state.shape) == 1:\n",
    "            # (1, x)\n",
    "            state = torch.unsqueeze(state, 0)\n",
    "            next_state = torch.unsqueeze(next_state, 0)\n",
    "            action = torch.unsqueeze(action, 0)\n",
    "            reward = torch.unsqueeze(reward, 0)\n",
    "            done = (done, )\n",
    "\n",
    "        # 1: predicted Q values with current state\n",
    "        pred = self.model(state)\n",
    "\n",
    "        target = pred.clone()\n",
    "        for idx in range(len(done)):\n",
    "            Q_new = reward[idx]\n",
    "            if not done[idx]:\n",
    "                Q_new = reward[idx] + self.gamma * torch.max(self.model(next_state[idx]))\n",
    "\n",
    "            target[idx][torch.argmax(action[idx]).item()] = Q_new\n",
    "    \n",
    "        # 2: Q_new = r + y * max(next_predicted Q value) -> only do this if not done\n",
    "        self.optimizer.zero_grad()\n",
    "        loss = self.criterion(target, pred)\n",
    "        loss.backward()\n",
    "\n",
    "        self.optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Plot function to display training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ion()\n",
    "\n",
    "def plot(scores, mean_scores):\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(plt.gcf())\n",
    "    plt.clf()\n",
    "    plt.title('Training...TriBlaster please be patient :)')\n",
    "    plt.xlabel('Number of Games')\n",
    "    plt.ylabel('Score')\n",
    "    plt.plot(scores)\n",
    "    plt.plot(mean_scores)\n",
    "    plt.ylim(ymin=0)\n",
    "    plt.text(len(scores)-1, scores[-1], str(scores[-1]))\n",
    "    plt.text(len(mean_scores)-1, mean_scores[-1], str(mean_scores[-1]))\n",
    "    plt.show(block=False)\n",
    "    plt.pause(.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train an Agent to play the SpaceShooter game "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_MEMORY = 100_000\n",
    "BATCH_SIZE = 1000\n",
    "\n",
    "# Learning rate\n",
    "LR = 0.001 \n",
    "\n",
    "class Agent:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.n_games = 0\n",
    "        self.epsilon = 0 # randomness\n",
    "        self.gamma = 0.9 # discount rate\n",
    "        self.memory = deque(maxlen=MAX_MEMORY) # popleft()\n",
    "        self.model = Linear_QNet(8, 256, 3)\n",
    "        self.trainer = QTrainer(self.model, lr=LR, gamma=self.gamma)\n",
    "\n",
    "\n",
    "    def get_state(self, game):\n",
    "        # yellow spaceship center\n",
    "        yellow_center = game.yellow.y + game.yellow.height//2\n",
    "        \n",
    "        # red spaceship center\n",
    "        red_center = game.red.y + game.red.height//2\n",
    "        \n",
    "        # Position of yellow_spaceship in next after taking action\n",
    "        position_up = yellow_center - VEL\n",
    "        position_down = yellow_center + VEL \n",
    "        \n",
    "        # Action\n",
    "        action_up = game.action == Action.UP\n",
    "        action_down = game.action == Action.DOWN\n",
    "        action_fire = game.action == Action.FIRE        \n",
    "        \n",
    "        # State \n",
    "        state = [\n",
    "            # If yellow spaceship fires from current position will it hit the red spaceship\n",
    "            (action_fire and yellow_center == red_center),\n",
    "            \n",
    "            # Will yellow spaceship be closer to red spaceship after taking an action\n",
    "            (action_up and abs(position_up - red_center) < abs(game.yellow.y - red_center)), # Action up\n",
    "            (action_down and abs(position_down - red_center) < abs(game.yellow.y - red_center)), # Action down\n",
    "            \n",
    "            # Current action\n",
    "            action_up,\n",
    "            action_down,\n",
    "            action_fire,\n",
    "            \n",
    "            # Direction of the red spaceship from yellow spaceship\n",
    "            yellow_center < red_center,  # red spaceship is below yellow spaceship\n",
    "            yellow_center > red_center   # red spaceship is above yellow spaceship\n",
    "            ]\n",
    "         \n",
    "        return np.array(state, dtype=int)\n",
    "    \n",
    "    \n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done)) # popleft if MAX_MEMORY is reached\n",
    "\n",
    "    def train_long_memory(self):\n",
    "        if len(self.memory) > BATCH_SIZE:\n",
    "            mini_sample = random.sample(self.memory, BATCH_SIZE) # list of tuples\n",
    "        else:\n",
    "            mini_sample = self.memory\n",
    "\n",
    "        states, actions, rewards, next_states, dones = zip(*mini_sample)\n",
    "        self.trainer.train_step(states, actions, rewards, next_states, dones)\n",
    "        \n",
    "    def train_short_memory(self, state, action, reward, next_state, done):\n",
    "        self.trainer.train_step(state, action, reward, next_state, done)\n",
    "\n",
    "    def get_action(self, state):\n",
    "        # random moves: tradeoff exploration / exploitation\n",
    "        self.epsilon = 80 - self.n_games\n",
    "        final_move = [0,0,0]\n",
    "        if random.randint(0, 200) < self.epsilon:\n",
    "            move = random.randint(0, 2)\n",
    "            final_move[move] = 1\n",
    "        else:\n",
    "            state0 = torch.tensor(state, dtype=torch.float)\n",
    "            prediction = self.model(state0)\n",
    "            move = torch.argmax(prediction).item()\n",
    "            final_move[move] = 1\n",
    "\n",
    "        return final_move\n",
    "\n",
    "\n",
    "def train():\n",
    "    plot_scores = []\n",
    "    plot_mean_scores = []\n",
    "    total_score = 0\n",
    "    record = 0\n",
    "    agent = Agent()\n",
    "    game = SpaceShooter()\n",
    "    \n",
    "    while True:\n",
    "        # get old state\n",
    "        state_old = agent.get_state(game)\n",
    "\n",
    "        # get move\n",
    "        final_move = agent.get_action(state_old)\n",
    "        \n",
    "        # perform move and get new state\n",
    "        done, score, reward = game.step(final_move)\n",
    "        state_new = agent.get_state(game)\n",
    "\n",
    "        # train short memory\n",
    "        agent.train_short_memory(state_old, final_move, reward, state_new, done)\n",
    "\n",
    "        # remember\n",
    "        agent.remember(state_old, final_move, reward, state_new, done)\n",
    "\n",
    "        if done:\n",
    "            # Train long memory, plot result\n",
    "            game.reset()\n",
    "            agent.n_games += 1\n",
    "            agent.train_long_memory()\n",
    "\n",
    "            if score > record:\n",
    "                record = score\n",
    "                agent.model.save()\n",
    "                \n",
    "            # Save model after a certain amount of games\n",
    "            if agent.n_games == 250:\n",
    "                agent.model.save_250()\n",
    "            if agent.n_games == 500:\n",
    "                agent.model.save_500()\n",
    "            if agent.n_games == 1000:\n",
    "                agent.model.save_1000()\n",
    "\n",
    "            plot_scores.append(score)\n",
    "            total_score += score\n",
    "            mean_score = total_score / agent.n_games\n",
    "            plot_mean_scores.append(mean_score)\n",
    "            plot(plot_scores, plot_mean_scores)\n",
    "                            \n",
    "            print('Game', agent.n_games, 'Score', score, 'Record:', record)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
